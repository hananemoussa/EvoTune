Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.15it/s]
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  3.50it/s]
Finetuning score threshold: -14850.89
Learning rate before schedule: 1e-05
Learning rate after schedule: 1.5811388300841898e-05
Finetuning with 72 chats
Extracting prompt in train dataset: 100%|██████████| 72/72 [00:00<00:00, 2658.92 examples/s]
Applying chat template to train dataset: 100%|██████████| 72/72 [00:00<00:00, 1263.01 examples/s]
Tokenizing train dataset: 100%|██████████| 72/72 [00:00<00:00, 139.28 examples/s]
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.
100%|██████████| 6/6 [02:03<00:00, 20.58s/it]
{'loss': 0.6931, 'grad_norm': 36.49457931518555, 'learning_rate': 1.5811388300841898e-05, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -839.9410400390625, 'logps/rejected': -809.5175170898438, 'logits/chosen': -1.6269128322601318, 'logits/rejected': -1.6736294031143188, 'epoch': 0.44}
{'loss': 0.6409, 'grad_norm': 16.395050048828125, 'learning_rate': 1.4752226119235527e-05, 'rewards/chosen': 0.9365386962890625, 'rewards/rejected': 0.6427139043807983, 'rewards/accuracies': 0.625, 'rewards/margins': 0.2938247621059418, 'logps/chosen': -816.7136840820312, 'logps/rejected': -809.380859375, 'logits/chosen': -1.6802618503570557, 'logits/rejected': -1.6823526620864868, 'epoch': 0.89}
{'loss': 0.4483, 'grad_norm': 121.56675720214844, 'learning_rate': 1.1858541225631424e-05, 'rewards/chosen': 1.188378930091858, 'rewards/rejected': -0.13140563666820526, 'rewards/accuracies': 0.875, 'rewards/margins': 1.3197845220565796, 'logps/chosen': -767.785888671875, 'logps/rejected': -805.3195190429688, 'logits/chosen': -1.7631466388702393, 'logits/rejected': -1.5684902667999268, 'epoch': 1.0}
{'loss': 4.5972, 'grad_norm': 5094.2265625, 'learning_rate': 7.905694150420949e-06, 'rewards/chosen': -0.27961575984954834, 'rewards/rejected': -0.7789840698242188, 'rewards/accuracies': 0.65625, 'rewards/margins': 0.49936825037002563, 'logps/chosen': -832.1991577148438, 'logps/rejected': -822.169921875, 'logits/chosen': -1.6459687948226929, 'logits/rejected': -1.635239839553833, 'epoch': 1.44}
{'loss': 0.3097, 'grad_norm': 140.76783752441406, 'learning_rate': 3.952847075210476e-06, 'rewards/chosen': 0.1132553219795227, 'rewards/rejected': -1.0977143049240112, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2109695672988892, 'logps/chosen': -812.8789672851562, 'logps/rejected': -809.3323974609375, 'logits/chosen': -1.611720085144043, 'logits/rejected': -1.6355599164962769, 'epoch': 1.89}
{'loss': 0.754, 'grad_norm': 895.601806640625, 'learning_rate': 1.0591621816063715e-06, 'rewards/chosen': -0.29583740234375, 'rewards/rejected': -1.3840759992599487, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0882384777069092, 'logps/chosen': -828.832275390625, 'logps/rejected': -783.2293090820312, 'logits/chosen': -1.7205853462219238, 'logits/rejected': -1.6364021301269531, 'epoch': 2.0}
{'train_runtime': 123.4707, 'train_samples_per_second': 1.166, 'train_steps_per_second': 0.049, 'train_loss': 1.2405432065327961, 'epoch': 2.0}
Unloading and merging model: 100%|██████████| 623/623 [00:00<00:00, 5100.36it/s]
