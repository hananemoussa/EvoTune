Finetuning score threshold: -608.1
Learning rate before schedule: 1e-05
Learning rate after schedule: 0.0001
Finetuning with 51 chats
Extracting prompt in train dataset: 100%|██████████| 51/51 [00:00<00:00, 2266.37 examples/s]
Applying chat template to train dataset: 100%|██████████| 51/51 [00:00<00:00, 1534.51 examples/s]
Tokenizing train dataset: 100%|██████████| 51/51 [00:00<00:00, 358.40 examples/s]
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 128009, 'pad_token_id': 128009}.
100%|██████████| 4/4 [00:33<00:00,  8.34s/it]
{'loss': 0.6931, 'grad_norm': 16.99690055847168, 'learning_rate': 0.0001, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -302.6283874511719, 'logps/rejected': -326.23394775390625, 'logits/chosen': 2.1379683017730713, 'logits/rejected': 2.13020658493042, 'epoch': 0.63}
{'loss': 0.4771, 'grad_norm': 17.415668487548828, 'learning_rate': 8.535533905932738e-05, 'rewards/chosen': 1.626816749572754, 'rewards/rejected': -0.05123000964522362, 'rewards/accuracies': 1.0, 'rewards/margins': 1.6780469417572021, 'logps/chosen': -303.3759460449219, 'logps/rejected': -276.9952697753906, 'logits/chosen': 2.176262617111206, 'logits/rejected': 2.1830999851226807, 'epoch': 1.0}
{'loss': 0.0198, 'grad_norm': 0.4275643229484558, 'learning_rate': 5e-05, 'rewards/chosen': 2.467176914215088, 'rewards/rejected': -2.787283182144165, 'rewards/accuracies': 1.0, 'rewards/margins': 5.254459381103516, 'logps/chosen': -295.8895263671875, 'logps/rejected': -309.9636535644531, 'logits/chosen': 2.2426347732543945, 'logits/rejected': 2.2571520805358887, 'epoch': 1.63}
{'loss': 0.0386, 'grad_norm': 1.2479578256607056, 'learning_rate': 1.4644660940672627e-05, 'rewards/chosen': 3.133105516433716, 'rewards/rejected': -3.8489654064178467, 'rewards/accuracies': 0.9473684430122375, 'rewards/margins': 6.982071876525879, 'logps/chosen': -300.57171630859375, 'logps/rejected': -325.6280212402344, 'logits/chosen': 2.3205220699310303, 'logits/rejected': 2.278815507888794, 'epoch': 2.0}
{'train_runtime': 33.3582, 'train_samples_per_second': 3.058, 'train_steps_per_second': 0.12, 'train_loss': 0.3071705256588757, 'epoch': 2.0}
Finetuning score threshold: -593.836
Learning rate before schedule: 1e-05
Learning rate after schedule: 0.0001
Finetuning with 49 chats
Extracting prompt in train dataset: 100%|██████████| 49/49 [00:00<00:00, 3633.49 examples/s]
Applying chat template to train dataset: 100%|██████████| 49/49 [00:00<00:00, 2524.30 examples/s]
Tokenizing train dataset: 100%|██████████| 49/49 [00:00<00:00, 354.55 examples/s]
100%|██████████| 4/4 [00:30<00:00,  7.70s/it]
{'loss': 0.6931, 'grad_norm': 16.743684768676758, 'learning_rate': 0.0001, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -306.4442138671875, 'logps/rejected': -304.79461669921875, 'logits/chosen': 2.3023295402526855, 'logits/rejected': 2.3116419315338135, 'epoch': 0.65}
{'loss': 0.4407, 'grad_norm': 23.08088493347168, 'learning_rate': 8.535533905932738e-05, 'rewards/chosen': 1.7178082466125488, 'rewards/rejected': -0.15878620743751526, 'rewards/accuracies': 0.9411764740943909, 'rewards/margins': 1.8765944242477417, 'logps/chosen': -280.4944763183594, 'logps/rejected': -347.4295959472656, 'logits/chosen': 2.262017250061035, 'logits/rejected': 2.2029550075531006, 'epoch': 1.0}
{'loss': 0.0197, 'grad_norm': 0.46131592988967896, 'learning_rate': 5e-05, 'rewards/chosen': 2.8087146282196045, 'rewards/rejected': -2.3585822582244873, 'rewards/accuracies': 1.0, 'rewards/margins': 5.167296886444092, 'logps/chosen': -284.56976318359375, 'logps/rejected': -319.6518859863281, 'logits/chosen': 2.2908647060394287, 'logits/rejected': 2.25199818611145, 'epoch': 1.65}
{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.4644660940672627e-05, 'rewards/chosen': 3.448026180267334, 'rewards/rejected': -3.77343487739563, 'rewards/accuracies': 1.0, 'rewards/margins': 7.221461772918701, 'logps/chosen': -304.1268310546875, 'logps/rejected': -339.5987854003906, 'logits/chosen': 2.3463022708892822, 'logits/rejected': 2.3967981338500977, 'epoch': 2.0}
{'train_runtime': 30.8191, 'train_samples_per_second': 3.18, 'train_steps_per_second': 0.13, 'train_loss': 0.28837721794843674, 'epoch': 2.0}
Finetuning score threshold: -579.572
Learning rate before schedule: 1e-05
Learning rate after schedule: 0.0001
Finetuning with 49 chats
Extracting prompt in train dataset: 100%|██████████| 49/49 [00:00<00:00, 3666.09 examples/s]
Applying chat template to train dataset: 100%|██████████| 49/49 [00:00<00:00, 2571.20 examples/s]
Tokenizing train dataset: 100%|██████████| 49/49 [00:00<00:00, 360.14 examples/s]
100%|██████████| 4/4 [00:30<00:00,  7.72s/it]
{'loss': 0.6931, 'grad_norm': 16.858272552490234, 'learning_rate': 0.0001, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -296.36090087890625, 'logps/rejected': -318.4093322753906, 'logits/chosen': 2.3616602420806885, 'logits/rejected': 2.382328987121582, 'epoch': 0.65}
{'loss': 0.5302, 'grad_norm': 18.841964721679688, 'learning_rate': 8.535533905932738e-05, 'rewards/chosen': 2.0270280838012695, 'rewards/rejected': 0.10531328618526459, 'rewards/accuracies': 0.9411764740943909, 'rewards/margins': 1.9217147827148438, 'logps/chosen': -272.690185546875, 'logps/rejected': -360.6422119140625, 'logits/chosen': 2.298410415649414, 'logits/rejected': 2.247962474822998, 'epoch': 1.0}
{'loss': 0.0275, 'grad_norm': 2.429702043533325, 'learning_rate': 5e-05, 'rewards/chosen': 2.6055498123168945, 'rewards/rejected': -2.594790458679199, 'rewards/accuracies': 1.0, 'rewards/margins': 5.2003397941589355, 'logps/chosen': -276.7009582519531, 'logps/rejected': -333.76275634765625, 'logits/chosen': 2.2927916049957275, 'logits/rejected': 2.2718424797058105, 'epoch': 1.65}
{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.4644660940672627e-05, 'rewards/chosen': 3.031775712966919, 'rewards/rejected': -3.9378437995910645, 'rewards/accuracies': 1.0, 'rewards/margins': 6.969619274139404, 'logps/chosen': -294.92388916015625, 'logps/rejected': -354.060302734375, 'logits/chosen': 2.332984447479248, 'logits/rejected': 2.401677370071411, 'epoch': 2.0}
{'train_runtime': 30.8993, 'train_samples_per_second': 3.172, 'train_steps_per_second': 0.129, 'train_loss': 0.31272753048688173, 'epoch': 2.0}
Finetuning score threshold: -565.308
Learning rate before schedule: 1e-05
Learning rate after schedule: 0.0001
Finetuning with 21 chats
Extracting prompt in train dataset: 100%|██████████| 21/21 [00:00<00:00, 2404.27 examples/s]
Applying chat template to train dataset: 100%|██████████| 21/21 [00:00<00:00, 1996.43 examples/s]
Tokenizing train dataset: 100%|██████████| 21/21 [00:00<00:00, 324.56 examples/s]
100%|██████████| 2/2 [00:12<00:00,  6.08s/it]
{'loss': 0.6931, 'grad_norm': 25.938953399658203, 'learning_rate': 0.0001, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -256.62548828125, 'logps/rejected': -359.39739990234375, 'logits/chosen': 2.3930294513702393, 'logits/rejected': 2.215909004211426, 'epoch': 1.0}
{'loss': 0.079, 'grad_norm': 12.946208953857422, 'learning_rate': 5e-05, 'rewards/chosen': 3.310215473175049, 'rewards/rejected': -1.2364554405212402, 'rewards/accuracies': 1.0, 'rewards/margins': 4.546671390533447, 'logps/chosen': -248.3499298095703, 'logps/rejected': -362.488525390625, 'logits/chosen': 2.297907590866089, 'logits/rejected': 2.149724245071411, 'epoch': 2.0}
{'train_runtime': 12.1571, 'train_samples_per_second': 3.455, 'train_steps_per_second': 0.165, 'train_loss': 0.3860968016088009, 'epoch': 2.0}
Finetuning score threshold: -551.044
Learning rate before schedule: 1e-05
Learning rate after schedule: 0.0001
Finetuning with 21 chats
Extracting prompt in train dataset: 100%|██████████| 21/21 [00:00<00:00, 2541.93 examples/s]
Applying chat template to train dataset: 100%|██████████| 21/21 [00:00<00:00, 2071.94 examples/s]
Tokenizing train dataset: 100%|██████████| 21/21 [00:00<00:00, 371.10 examples/s]
100%|██████████| 2/2 [00:12<00:00,  6.09s/it]
{'loss': 0.6931, 'grad_norm': 31.613801956176758, 'learning_rate': 0.0001, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -235.40269470214844, 'logps/rejected': -379.54620361328125, 'logits/chosen': 2.1936328411102295, 'logits/rejected': 2.093601942062378, 'epoch': 1.0}
{'loss': 0.0382, 'grad_norm': 4.733434200286865, 'learning_rate': 5e-05, 'rewards/chosen': 3.717844009399414, 'rewards/rejected': -1.8979341983795166, 'rewards/accuracies': 1.0, 'rewards/margins': 5.61577844619751, 'logps/chosen': -226.10812377929688, 'logps/rejected': -384.291015625, 'logits/chosen': 1.9882445335388184, 'logits/rejected': 1.9509137868881226, 'epoch': 2.0}
{'train_runtime': 12.181, 'train_samples_per_second': 3.448, 'train_steps_per_second': 0.164, 'train_loss': 0.3656670469790697, 'epoch': 2.0}
Unloading and merging model: 100%|██████████| 327/327 [00:00<00:00, 4438.09it/s]
